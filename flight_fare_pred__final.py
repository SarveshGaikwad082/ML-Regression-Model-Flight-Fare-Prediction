# -*- coding: utf-8 -*-
"""flight_fare_pred _final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KDkc8DtBQv9qqUB3glp1qf22RiPubELj

# Problem Statement
Create a regression model to predict flight fares using features like departure and arrival locations, flight duration, airline, and travel date. The aim is to accurately estimate flight prices, helping travelers with their planning and airlines with their pricing strategies.

# Data Preparetion:
data = https://docs.google.com/spreadsheets/d/1BBA4uUf6b4gd8JaJdlFRXvzxZtb4djWj/edit?usp=drive_link&ouid=114815927267366108906&rtpof=true&sd=true
"""

# Commented out IPython magic to ensure Python compatibility.
# Load Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from google.colab import drive
drive.mount('/content/mount/')

# Load Data
train_data = pd.read_excel(r"/content/mount/MyDrive/csv_files/ML PR REG1/fligh_fare_train_data.xlsx")
train_data.head()

# shape of train_data
train_data.shape

train_data.info()

train_data.describe()

"""Observation: There are potential outliers in the "Price" column, especially at the higher end, as indicated by the max value, which is significantly higher than the Interquartile Range."""

# check the Distribution of "Price" Columns
plt.figure(figsize = (10,5))
plt.subplot(1,2,1)
sns.histplot(train_data['Price'],kde = True)
print(f"Skewness:{train_data['Price'].skew():.4f}")

plt.subplot(1,2,2)
train_data["Price"].plot(kind = "box")

plt.tight_layout()

"""Observation:
The "Price" column distribution is positively skewed with skewness of 1.8126 , indicting longer tail on the hihger end.
"""

# Outlier detect and remove by z-score method
mean = train_data["Price"].mean()
std = train_data["Price"].std()
treshold = 3
train_data["Z-score"] = np.abs((train_data["Price"]-mean)/std)
outlier = train_data[train_data["Z-score"]>treshold]
print(f"There are {len(outlier)} outlier in the 'Price' column")
print(f"Index of Outlier are {outlier.index}")

# drop the Outlier from train_data
 train_data = train_data.drop(outlier.index)

train_data.shape

"""## Handling missing Value"""

train_data.isnull().sum()

# There is only one null value we remove .
train_data = train_data.dropna()

# check Duplicate Value
train_data.duplicated().sum()

# There are 220 duplicated value lets remove and keep first value
train_data = train_data.drop_duplicates(keep="first")

train_data.duplicated().sum()

# DONE!

"""## Feature Engineering"""

train_data.head()

# let's split the "Date_of_Journey".
train_data["Date_of_Journey"] = pd.to_datetime(train_data["Date_of_Journey"])
train_data["Day"] = train_data["Date_of_Journey"].dt.day
train_data["Month"] = train_data["Date_of_Journey"].dt.month
train_data["Year"] = train_data["Date_of_Journey"].dt.year
train_data["Day_of_week"] = train_data["Date_of_Journey"].dt.day_name()

# let's split "Dep_Time" into "Dep_Hour" and "Dep_Min"
train_data["Dep_Houe"] = train_data["Dep_Time"].str.split(":").str[0].astype("int64")
train_data["Dep_Min"] = train_data["Dep_Time"].str.split(":").str[1].astype("int64")

# lets split "Arrival_Time" into "Arrival_Hour" and "Arrival_Min"
train_data['Arrival_Hour'] = train_data['Arrival_Time'].str.split(':').str[0].astype('int64')
train_data['Arrival_Minute'] = train_data['Arrival_Time'].str.split(':').str[1].str.split(' ').str[0].astype('int64')

# let's "Duration" convert  to min column
train_data['Duration'].unique()

"""Observation:
In "Duration" column there are only "m" suffix value this (stands for) is not possible so search and delete.
"""

train_data["Duration_h"] = train_data["Duration"].str.split(" ").str[0].str.replace("h","")
train_data[train_data["Duration_h"].str.contains("m")]

train_data = train_data.drop([6474],axis = 0)

train_data["Duration_h"] = train_data["Duration_h"].astype("int64")

train_data["Duration_m"] = train_data["Duration"].str.split(" ").str[1]
print(f"Null Value in 'Duration_m' column {train_data['Duration_m'].isnull().sum()}")
print("replace with '0' value")
train_data["Duration_m"] = train_data["Duration_m"].fillna("0")
train_data["Duration_m"] = train_data["Duration_m"].str.replace("m","").astype("int64")
train_data.head(3)

train_data["Duration"] = train_data["Duration_h"]*60 + train_data["Duration_m"]

# divide Route Column
train_data["Route1"] = train_data["Route"].str.split("→").str[0].fillna('None')
train_data["Route2"] = train_data["Route"].str.split("→").str[1].fillna('None')
train_data["Route3"] = train_data["Route"].str.split("→").str[2].fillna('None')
train_data["Route4"] = train_data["Route"].str.split("→").str[3].fillna('None')
train_data["Route5"] = train_data["Route"].str.split("→").str[4].fillna('None')

train_data[['Total_Stops', 'Route']]

# by simple visualization we can can see there is realtion that in route column if remove source and destination then its remaning stops should be total_stops
train_data["Total_Stops"] = train_data["Route"].apply(lambda x:len(x.split(" → "))-2)

train_data.head(3)

"""# Preprocess Data

# EDA
"""

# Airline
train_data["Airline"].value_counts()

# barplot to show the user count of Airline Categories
plt.figure(figsize=(10.8, 6))
sns.barplot(x=train_data["Airline"].value_counts().values,
            y=train_data["Airline"].value_counts().index)
plt.title('User Count of Airline Categories')
plt.xlabel('User Count')
plt.ylabel('Airline')
plt.show()

mean_price_per_airline = train_data.groupby("Airline").agg({'Price': 'mean'}).reset_index().sort_values(by="Price", ascending = False)
mean_price_per_airline.rename(columns={'Price': 'Mean_Price'}, inplace=True)
print(mean_price_per_airline)

# Create a bar plot
plt.figure(figsize=(12, 8))
sns.barplot(x='Mean_Price', y='Airline', data=mean_price_per_airline, palette='viridis')
plt.title('Average Price per Airline')
plt.xlabel('average Price')
plt.ylabel('Airline')
plt.show()

data = train_data.sort_values(by="Date_of_Journey")
daily_fare_sorted = data.groupby('Date_of_Journey')['Price'].mean().reset_index()
plt.figure(figsize=(12, 6))
sns.lineplot(data=daily_fare_sorted, x='Date_of_Journey', y='Price', marker='o')
plt.title('Average Fare Distribution Over Days')
plt.xlabel('Date of Journey')
plt.ylabel('Average Price')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.grid()
plt.show()

# drop old and irrleveant column
train_data = train_data.drop(["Date_of_Journey","Route","Dep_Time","Arrival_Time","Additional_Info","Z-score","Duration_h","Duration_m"],axis=1)

"""## Encoding Categorical Variables"""

train_data.info()

# lets Do One Hot encoding on Categorical column
categorical_column = train_data.select_dtypes(include="object").columns
categorical_column = pd.get_dummies(train_data[categorical_column],drop_first=True)

categorical_column = categorical_column.astype("int64")

train_data = pd.concat([train_data,categorical_column],axis=1)

train_data

train_data = train_data.drop(['Airline', 'Source', 'Destination', 'Day_of_week', 'Route1', 'Route2',
       'Route3', 'Route4', 'Route5'],axis=1)

train_data

"""## Split Data"""

x = train_data.drop(["Price"],axis=1)
y =train_data["Price"]

x.shape

y.shape

"""## Correlation Analysis and VIF Calculation for Feature Selection"""

plt.figure(figsize=(10,10))
sns.heatmap(x.corr(), annot=True, cmap='coolwarm')

threshold = 0.8
corr_matrix = x.corr()
high_corr_var = np.where(abs(corr_matrix) > threshold)
high_corr_var = [(corr_matrix.index[x], corr_matrix.columns[y])
                 for x, y in zip(*high_corr_var) if x != y and x < y]

high_corr_var

from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = pd.DataFrame()
vif["Feature"] = x.columns
vif["VIF"] = [variance_inflation_factor(x.values,i) for i in range (x.shape[1])]
print(vif.sort_values(by="VIF",ascending=False))

# Suppress warnings
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)

# let's remove high VIF value Feature
max_vif = 10
remove_column = True

while remove_column:
    vif = pd.DataFrame()
    vif["Feature"] = x.columns
    vif["VIF"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]

    max_vif_feature = vif.loc[vif["VIF"].idxmax()]

    if max_vif_feature["VIF"] > max_vif:
        x = x.drop(max_vif_feature["Feature"],axis=1)
        print(f"Removed feature '{max_vif_feature['Feature']}' with VIF = {max_vif_feature['VIF']:.2f}")
    else:
        remove_column = False

print(x.columns)
print(f"Remaining feature {(x.shape[1])}")

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state = 42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train_sc = scaler.fit_transform(x_train)
x_test_sc = scaler.transform(x_test)

x_test_sc

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import cross_val_score,GridSearchCV

"""# Model Building

"""

models = {
    "LinearRegression":LinearRegression(),
    "DecisionTreeRegressor":DecisionTreeRegressor(),
    "RandomForestRegressor":RandomForestRegressor(),
    "GradientBoostingRegressor":GradientBoostingRegressor(),
    "XGBRegressor":XGBRegressor(),
    "AdaBoostRegressor":AdaBoostRegressor(),
    "SVR":SVR(),
    "KNeighborsRegressor":KNeighborsRegressor()
}

result = []

for model_name,model in models.items():
  model.fit(x_train_sc,y_train)
  y_pred = model.predict(x_test_sc)
  score = model.score(x_train_sc, y_train)
  test_score = model.score(x_test_sc, y_test)


  result.append({
      "Model": model_name,
      "train R²": score,
      "test R²": test_score
  })

  df = pd.DataFrame(result)
  df = pd.DataFrame(result)

print(df)

df["train R²"] = df["train R²"].apply(lambda x: f"{x * 100:.2f}%")
df["test R²"] = df["test R²"].apply(lambda x: f"{x * 100:.2f}%")

print(df)

"""# observation:
1) **RandomForestRegressor** demonstrates strong performance with a high training R² of 94.68% and a decent test R² of 79.04%, indicating good generalization but a slight risk of overfitting compared to other models like **DecisionTreeRegressor**, which shows a high train R² of 96.13% but a much lower test R² of 67.46%, suggesting overfitting.

2) **XGBRegressor** is selected for its balanced performance, with a** training R² of 90.67%** and the **highest test R² of 84.39%**, indicating that it generalizes well to unseen data and outperforms other models in terms of both accuracy and robustness.

3) ***GradientBoostingRegressor and KNeighborsRegressor *** also show decent test R² scores, but XGBRegressor is preferred for its ability to consistently deliver high accuracy across both training and test sets, making it the most reliable model for this problem..

## Hyperparameter Training
"""

xgb = XGBRegressor()
xgb.fit(x_train,y_train)
y_pred = xgb.predict(x_test)

from sklearn.model_selection import RandomizedSearchCV , GridSearchCV
params = {
    "learning_rate" : [0.05,0.1,0.15,0.20,0.25,0.30],
    "max_depth" : [3,4,5,6,8,9,10,11,12],
    "min_child_weight" : [1,3,5,7],
    "gamma" : [0.0,0.1,0.2,0.3,0.4],
    "colsample_bytree" : [0.3,0.4,0.5,0.6]
}
random_search = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=params,  # Use param_distributions for RandomizedSearchCV
    scoring="r2",
    n_jobs=-1,
    cv=5,
    n_iter=100,  # Number of parameter settings that are sampled
    verbose=3
)

random_search.fit(x_train_sc, y_train)
print(f"Best Score: {random_search.best_score_}")
print(f"Best Params: {random_search.best_params_}")

from sklearn.model_selection import cross_val_score
xgb_best = XGBRegressor(
    min_child_weight=3,
    max_depth=6,
    learning_rate=0.3,
    gamma=0.1,
    colsample_bytree=0.6
)
cv_score = cross_val_score(xgb_best,x_train_sc,y_train,cv=10)
print(f"cross validation : {cv_score}")
print(f"cross validation : {cv_score.mean()}")

"""Observation:

The XGBRegressor model demonstrates reliable and effective performance with a mean R² score of approximately 0.84, indicating strong predictive capability. The consistent scores across cross-validation folds reflect good generalization to unseen data. The current hyperparameters are well-suited for the dataset, ensuring robust performance.
"""

xgb_best = XGBRegressor(
    min_child_weight=3,
    max_depth=9,
    learning_rate=0.15,
    gamma=0.0,
    colsample_bytree=0.5
)
xgb_best.fit(x_train_sc,y_train)
y_pred = xgb_best.predict(x_test_sc)
print(f"Model train score: {xgb_best.score(x_train_sc, y_train):.4f}")
print(f"Model test score: {xgb_best.score(x_test_sc, y_test):.4f}")
print(f"R² score: {r2_score(y_test, y_pred):.4f}")

"""Observation:
After applying hyperparameter tuning, the model achieved a train score of 0.9224 and a test score of 0.8370, indicating a well-generalized model with consistent performance.

## Heteroscadscity
"""

# check for there is availibilty of heteroscadscity
residuals = y_test - y_pred

plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals,alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted value')
plt.ylabel('Residuals')
plt.title('Residuals vs. Predicted value')
plt.show()

"""Observation:

By visualizing the graph of predictions vs. residuals, it is evident that the variance of residuals is not constant across different levels of predicted values. This indicates the presence of heteroscedasticity in the model.
"""

import statsmodels.api as sm
from statsmodels.stats.diagnostic import het_white
X_train_with_const = sm.add_constant(x_train_sc)
model = sm.OLS(y_train, X_train_with_const).fit()
residuals = model.resid
white_test = het_white(residuals, X_train_with_const)
white_test_statistic, white_test_pvalue, _, _ = white_test
print(f'White test statistic: {white_test_statistic}')
print(f'White test p-value: {white_test_pvalue}')

"""Observation:

The White test indicates a strong presence of heteroscedasticity in the model, as evidenced by the extremely high test statistic and an almost zero p-value.
"""

# Use log transformation to reduce Heterscoacity
y_train_log = np.log1p(y_train)
y_test_log = np.log1p(y_test)


xgb_log = XGBRegressor()
xgb_log.fit(x_train_sc, y_train_log)


y_pred_log = xgb_log.predict(x_test_sc)
y_pred_exp = np.expm1(y_pred_log)


from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_pred_exp)
print(f'R² score with log transformation: {r2}')

"""# Final Result:
1) The final **XGBRegressor** model, after applying **log transformation**, achieved an **R² score of 0.848**, indicating an improvement in predictive performance compared to the original model. The original model had a training R² score of 0.9105 and a test R² score of 0.8376

2) The log transformation improved the model's fit and accuracy by reducing heteroscedasticity and enhancing performance
"""

import pickle
# Save the log-transformed model
with open("xgb_log.pkl", "wb") as f:
    pickle.dump(xgb_log, f)

# Load the log-transformed model
with open("xgb_log.pkl", "rb") as f:
    xgb_log_loaded = pickle.load(f)

y_pred_log_loaded = xgb_log_loaded.predict(x_test_sc)
y_pred_exp_loaded = np.expm1(y_pred_log_loaded)
r2_loaded = r2_score(y_test, y_pred_exp_loaded)
print(f'R² score with loaded log-transformed model: {r2_loaded}')

# DONE

